{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retailer Sales Data Forecasting\n",
    "\n",
    "This dataset contains the daily sales data of a US retailer.  \n",
    "Your objective is to forecast the total sales for each State over the next 12 months, using the historical data provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Top-Down Approach\n",
    "\n",
    "1. **Aggregate Sales:**  \n",
    "   Combine the sales data to create total sales at the `year-month` level, using the `Order Date` as the time variable for aggregation.\n",
    "\n",
    "\n",
    "2. **Train a Model:**  \n",
    "   Using the aggregated `year-month` data, train a model to forecast the total sales for the next 12 months.  \n",
    "   *(The choice of model is up to you.)*\n",
    "\n",
    "3. **Disaggregate Predictions:**  \n",
    "   Split the predicted sales from the `year-month` level back to the `year-month-State` level.  \n",
    "   *(The splitting strategy is up to you.)*\n",
    "\n",
    "4. **Evaluate Accuracy:**  \n",
    "   Assess the forecast accuracy at both the `year-month` and `year-month-State` levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Alternative Approach\n",
    "\n",
    "- Implement a different approach to forecast the next 12 months of sales at the `year-month-State` level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Retailer Sales Data.csv')\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\n",
    "\n",
    "\n",
    "# Drop rows where 'State' is missing (we need state-level forecasts)\n",
    "df_cleaned = df.dropna(subset=['State'])\n",
    "\n",
    "# Create 'Year-Month' column from 'Order Date'\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "\n",
    "# Aggregate sales at the 'Year-Month' level\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "\n",
    "# Convert 'Year-Month' back to a datetime format for consistency\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for time series forecasting\n",
    "monthly_sales.set_index('Year-Month', inplace=True)\n",
    "\n",
    "# Apply Exponential Smoothing model (Holt-Winters method)\n",
    "model = ExponentialSmoothing(monthly_sales['Sales'], trend='add', seasonal=None, seasonal_periods=12)\n",
    "hw_model = model.fit()\n",
    "\n",
    "# Forecast the next 12 months\n",
    "forecast_periods = 12\n",
    "forecast = hw_model.forecast(steps=forecast_periods)\n",
    "\n",
    "# Generate future dates for the forecast\n",
    "future_dates = pd.date_range(start=monthly_sales.index[-1] + pd.DateOffset(months=1), periods=forecast_periods, freq='MS')\n",
    "\n",
    "# Combine forecast with future dates\n",
    "forecast_df = pd.DataFrame({'Year-Month': future_dates, 'Forecasted Sales': forecast})\n",
    "\n",
    "# Show the forecasted results\n",
    "forecast_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate historical state-wise proportions\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "\n",
    "# Aggregate sales by 'Year-Month' and 'State'\n",
    "statewise_monthly_sales = df_cleaned.groupby(['Year-Month', 'State'])['Sales'].sum().reset_index()\n",
    "\n",
    "# Calculate state-wise sales as a proportion of the total sales in that month\n",
    "statewise_monthly_sales['Year-Month'] = statewise_monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "total_monthly_sales = statewise_monthly_sales.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "\n",
    "# Merge the total monthly sales with the state-wise sales\n",
    "statewise_monthly_sales = pd.merge(statewise_monthly_sales, total_monthly_sales, on='Year-Month', suffixes=('', '_Total'))\n",
    "\n",
    "# Calculate the proportion of state sales\n",
    "statewise_monthly_sales['Sales_Proportion'] = statewise_monthly_sales['Sales'] / statewise_monthly_sales['Sales_Total']\n",
    "\n",
    "# Use the last available month's proportions for disaggregation of the forecast\n",
    "last_known_month = statewise_monthly_sales[statewise_monthly_sales['Year-Month'] == statewise_monthly_sales['Year-Month'].max()]\n",
    "\n",
    "# Disaggregate the forecast based on the proportions from the last known month\n",
    "disaggregated_forecast = []\n",
    "\n",
    "for _, forecast_row in forecast_df.iterrows():\n",
    "    forecast_month = forecast_row['Year-Month']\n",
    "    forecast_value = forecast_row['Forecasted Sales']\n",
    "    \n",
    "    # Apply the state-wise proportions from the last available month\n",
    "    for _, proportion_row in last_known_month.iterrows():\n",
    "        state = proportion_row['State']\n",
    "        proportion = proportion_row['Sales_Proportion']\n",
    "        state_forecast = forecast_value * proportion\n",
    "        \n",
    "        disaggregated_forecast.append({\n",
    "            'Year-Month': forecast_month,\n",
    "            'State': state,\n",
    "            'Forecasted Sales': state_forecast\n",
    "        })\n",
    "\n",
    "# Convert disaggregated forecast to DataFrame\n",
    "disaggregated_forecast_df = pd.DataFrame(disaggregated_forecast)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Assuming 'monthly_sales' is your complete historical dataset\n",
    "# Split data into training and testing sets (e.g., last 12 months for testing)\n",
    "train_data = monthly_sales[:-12]\n",
    "test_data = monthly_sales[-12:]\n",
    "\n",
    "# Train the model on the training data\n",
    "model = ExponentialSmoothing(train_data['Sales'], trend='add', seasonal=None, seasonal_periods=12)\n",
    "hw_model = model.fit()\n",
    "\n",
    "# Forecast the same period as the test data\n",
    "predictions = hw_model.forecast(steps=12)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = mean_absolute_error(test_data['Sales'], predictions)\n",
    "rmse = mean_squared_error(test_data['Sales'], predictions, squared=False)\n",
    "mape = np.mean(np.abs((test_data['Sales'] - predictions) / test_data['Sales'])) * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Train-test split (usiamo gli ultimi 12 mesi per il test)\n",
    "train_data = monthly_sales[:-12]\n",
    "test_data = monthly_sales[-12:]\n",
    "\n",
    "# Addestramento del modello SARIMA con i parametri di esempio (puoi regolarli in base alla situazione)\n",
    "sarima_model = SARIMAX(train_data['Sales'], \n",
    "                       order=(1, 1, 1),  # Parametri ARIMA(p, d, q)\n",
    "                       seasonal_order=(1, 1, 1, 12))  # Parametri stagionali (P, D, Q, S) con stagionalità annuale\n",
    "\n",
    "sarima_fit = sarima_model.fit(disp=False)\n",
    "\n",
    "# Fare previsioni per i 12 mesi del test\n",
    "sarima_predictions = sarima_fit.forecast(steps=12)\n",
    "\n",
    "# Calcolare le metriche di errore\n",
    "mae_sarima = mean_absolute_error(test_data['Sales'], sarima_predictions)\n",
    "rmse_sarima = mean_squared_error(test_data['Sales'], sarima_predictions, squared=False)\n",
    "mape_sarima = np.mean(np.abs((test_data['Sales'] - sarima_predictions) / test_data['Sales'])) * 100\n",
    "\n",
    "# Stampare i risultati\n",
    "print(f'Mean Absolute Error (MAE) - SARIMA: {mae_sarima}')\n",
    "print(f'Root Mean Squared Error (RMSE) - SARIMA: {rmse_sarima}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - SARIMA: {mape_sarima}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print il min e max df_cleaned['Year-Month']\n",
    "print(df_cleaned['Year-Month'].min())\n",
    "print(df_cleaned['Year-Month'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Supponiamo che 'df_cleaned' sia il dataframe pulito e pronto all'uso\n",
    "# Aggregazione delle vendite a livello 'year-month'\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n",
    "# Train-test split (usiamo gli ultimi 12 mesi per il test)\n",
    "train_data = monthly_sales[:-12]\n",
    "test_data = monthly_sales[-12:]\n",
    "\n",
    "# Addestramento del modello SARIMA\n",
    "sarima_model = SARIMAX(train_data['Sales'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "sarima_fit = sarima_model.fit(disp=False)\n",
    "\n",
    "# Fare previsioni per i prossimi 12 mesi\n",
    "sarima_predictions = sarima_fit.forecast(steps=12)\n",
    "\n",
    "# Calcolo delle metriche di errore a livello aggregato\n",
    "mae_sarima = mean_absolute_error(test_data['Sales'], sarima_predictions)\n",
    "rmse_sarima = mean_squared_error(test_data['Sales'], sarima_predictions, squared=False)\n",
    "mape_sarima = np.mean(np.abs((test_data['Sales'] - sarima_predictions) / test_data['Sales'])) * 100\n",
    "\n",
    "# Stampa delle metriche di errore\n",
    "print(f'Mean Absolute Error (MAE) - SARIMA: {mae_sarima}')\n",
    "print(f'Root Mean Squared Error (RMSE) - SARIMA: {rmse_sarima}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - SARIMA: {mape_sarima}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione di un dataframe con le previsioni e le date future\n",
    "future_dates = pd.date_range(start=monthly_sales['Year-Month'].max() + pd.DateOffset(months=1), periods=12, freq='MS')\n",
    "forecast_df = pd.DataFrame({'Year-Month': future_dates, 'Forecasted Sales': sarima_predictions})\n",
    "\n",
    "### DISAGGREGAZIONE DELLE PREVISIONI A LIVELLO DI STATO ###\n",
    "\n",
    "# Aggregazione delle vendite a livello 'year-month-state' per calcolare le proporzioni storiche\n",
    "statewise_monthly_sales = df_cleaned.groupby(['Year-Month', 'State'])['Sales'].sum().reset_index()\n",
    "\n",
    "# Assicurati che la colonna 'Year-Month' sia di tipo Period\n",
    "#statewise_monthly_sales['Year-Month'] = statewise_monthly_sales['Year-Month'].dt.to_period('M')\n",
    "\n",
    "# Calcolo della proporzione delle vendite per stato rispetto al totale mensile\n",
    "total_monthly_sales = statewise_monthly_sales.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "statewise_monthly_sales = pd.merge(statewise_monthly_sales, total_monthly_sales, on='Year-Month', suffixes=('', '_Total'))\n",
    "statewise_monthly_sales['Sales_Proportion'] = statewise_monthly_sales['Sales'] / statewise_monthly_sales['Sales_Total']\n",
    "\n",
    "# Usare l'ultimo mese disponibile per calcolare le proporzioni di disaggregazione\n",
    "last_known_month = statewise_monthly_sales[statewise_monthly_sales['Year-Month'] == statewise_monthly_sales['Year-Month'].max()]\n",
    "\n",
    "# Disaggregare le previsioni basandosi sulle proporzioni dell'ultimo mese disponibile\n",
    "disaggregated_forecast = []\n",
    "\n",
    "for _, forecast_row in forecast_df.iterrows():\n",
    "    forecast_month = forecast_row['Year-Month'].to_period('M')  # Assicurati che questo sia un Period\n",
    "    forecast_value = forecast_row['Forecasted Sales']\n",
    "    \n",
    "    # Applica le proporzioni storiche di ciascuno stato\n",
    "    for _, proportion_row in last_known_month.iterrows():\n",
    "        state = proportion_row['State']\n",
    "        proportion = proportion_row['Sales_Proportion']\n",
    "        state_forecast = forecast_value * proportion\n",
    "        \n",
    "        disaggregated_forecast.append({\n",
    "            'Year-Month': forecast_month,\n",
    "            'State': state,\n",
    "            'Forecasted Sales': state_forecast\n",
    "        })\n",
    "\n",
    "# Converti le previsioni disaggregate in un dataframe\n",
    "disaggregated_forecast_df = pd.DataFrame(disaggregated_forecast)\n",
    "\n",
    "# Mostra il risultato delle previsioni disaggregate\n",
    "print(disaggregated_forecast_df.head())\n",
    "\n",
    "### VALUTAZIONE A LIVELLO DI STATO ###\n",
    "# Calcola la data minima nel periodo di test e convertila in Period\n",
    "test_data_min_date = pd.to_datetime(test_data['Year-Month'].min()).to_period('M')\n",
    "\n",
    "# Filtro sulle vendite effettive a livello di stato, a partire dalla data minima del periodo di test\n",
    "actual_state_sales = statewise_monthly_sales[statewise_monthly_sales['Year-Month'] >= test_data_min_date]\n",
    "\n",
    "# Mostra i risultati per verificare che il confronto avvenga correttamente\n",
    "print(actual_state_sales.head())\n",
    "\n",
    "# Calcola le metriche a livello di stato (se hai i dati effettivi da confrontare)\n",
    "# MAE, RMSE, e MAPE possono essere calcolati per ciascuno stato allo stesso modo delle previsioni mensili\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Retailer Sales Data.csv')\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\n",
    "\n",
    "\n",
    "# Drop rows where 'State' is missing (we need state-level forecasts)\n",
    "df_cleaned = df.dropna(subset=['State'])\n",
    "\n",
    "# Create 'Year-Month' column from 'Order Date'\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "\n",
    "# Aggregate sales at the 'Year-Month' level\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "\n",
    "# Convert 'Year-Month' back to a datetime format for consistency\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n",
    "\n",
    "\n",
    "# Supponiamo che 'df_cleaned' sia il dataframe pulito e pronto all'uso\n",
    "# Aggregazione delle vendite a livello 'year-month'\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n",
    "# Impostiamo i dati di addestramento fino a dicembre 2017 e usiamo il 2018 per il test\n",
    "train_data = monthly_sales[monthly_sales['Year-Month'] < '2018-01-01']\n",
    "test_data = monthly_sales[monthly_sales['Year-Month'] >= '2018-01-01']\n",
    "\n",
    "# Addestramento del modello SARIMA\n",
    "sarima_model = SARIMAX(train_data['Sales'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "sarima_fit = sarima_model.fit(disp=False)\n",
    "\n",
    "# Fare previsioni per tutto il 2018 (12 mesi)\n",
    "sarima_predictions = sarima_fit.forecast(steps=len(test_data))\n",
    "\n",
    "# Calcolo delle metriche di errore a livello aggregato\n",
    "mae_sarima = mean_absolute_error(test_data['Sales'], sarima_predictions)\n",
    "rmse_sarima = mean_squared_error(test_data['Sales'], sarima_predictions, squared=False)\n",
    "mape_sarima = np.mean(np.abs((test_data['Sales'] - sarima_predictions) / test_data['Sales'])) * 100\n",
    "\n",
    "# Stampa delle metriche di errore\n",
    "print(f'Mean Absolute Error (MAE) - SARIMA: {mae_sarima}')\n",
    "print(f'Root Mean Squared Error (RMSE) - SARIMA: {rmse_sarima}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - SARIMA: {mape_sarima}%')\n",
    "\n",
    "# Creazione di un dataframe con le previsioni e le date future\n",
    "future_dates = pd.date_range(start=test_data['Year-Month'].min(), periods=len(test_data), freq='MS')\n",
    "forecast_df = pd.DataFrame({'Year-Month': future_dates, 'Forecasted Sales': sarima_predictions})\n",
    "\n",
    "### DISAGGREGAZIONE DELLE PREVISIONI A LIVELLO DI STATO ###\n",
    "\n",
    "# Aggregazione delle vendite a livello 'year-month-state' per calcolare le proporzioni storiche\n",
    "statewise_monthly_sales = df_cleaned.groupby(['Year-Month', 'State'])['Sales'].sum().reset_index()\n",
    "\n",
    "# Calcolo della proporzione delle vendite per stato rispetto al totale mensile\n",
    "total_monthly_sales = statewise_monthly_sales.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "statewise_monthly_sales = pd.merge(statewise_monthly_sales, total_monthly_sales, on='Year-Month', suffixes=('', '_Total'))\n",
    "statewise_monthly_sales['Sales_Proportion'] = statewise_monthly_sales['Sales'] / statewise_monthly_sales['Sales_Total']\n",
    "\n",
    "# Usare l'ultimo mese disponibile per calcolare le proporzioni di disaggregazione\n",
    "last_known_month = statewise_monthly_sales[statewise_monthly_sales['Year-Month'] == statewise_monthly_sales['Year-Month'].max()]\n",
    "\n",
    "# Disaggregare le previsioni basandosi sulle proporzioni dell'ultimo mese disponibile\n",
    "disaggregated_forecast = []\n",
    "\n",
    "for _, forecast_row in forecast_df.iterrows():\n",
    "    forecast_month = forecast_row['Year-Month'].to_period('M')  # Assicurati che questo sia un Period\n",
    "    forecast_value = forecast_row['Forecasted Sales']\n",
    "    \n",
    "    # Applica le proporzioni storiche di ciascuno stato\n",
    "    for _, proportion_row in last_known_month.iterrows():\n",
    "        state = proportion_row['State']\n",
    "        proportion = proportion_row['Sales_Proportion']\n",
    "        state_forecast = forecast_value * proportion\n",
    "        \n",
    "        disaggregated_forecast.append({\n",
    "            'Year-Month': forecast_month,\n",
    "            'State': state,\n",
    "            'Forecasted Sales': state_forecast\n",
    "        })\n",
    "\n",
    "# Converti le previsioni disaggregate in un dataframe\n",
    "disaggregated_forecast_df = pd.DataFrame(disaggregated_forecast)\n",
    "\n",
    "# Mostra il risultato delle previsioni disaggregate\n",
    "print(disaggregated_forecast_df.head())\n",
    "\n",
    "### VALUTAZIONE A LIVELLO DI STATO ###\n",
    "# Calcola le metriche a livello di stato (se hai i dati effettivi da confrontare)\n",
    "\n",
    "# Unisci i dati reali con le previsioni\n",
    "merged_df = pd.merge(\n",
    "    disaggregated_forecast_df,\n",
    "    statewise_monthly_sales[statewise_monthly_sales['Year-Month'] >= '2018-01-01'],\n",
    "    on=['Year-Month', 'State'],\n",
    "    how='left',\n",
    "    suffixes=('_Forecast', '_Actual')\n",
    ")\n",
    "\n",
    "# Calcola le metriche per ciascuno stato\n",
    "metrics = []\n",
    "\n",
    "# Itera attraverso ciascuno stato\n",
    "for state in merged_df['State'].unique():\n",
    "    state_data = merged_df[merged_df['State'] == state]\n",
    "    \n",
    "    # Calcola MAE\n",
    "    mae = np.mean(np.abs(state_data['Forecasted Sales'] - state_data['Sales']))\n",
    "    \n",
    "    # Calcola RMSE\n",
    "    rmse = np.sqrt(np.mean((state_data['Forecasted Sales'] - state_data['Sales']) ** 2))\n",
    "    \n",
    "    # Calcola MAPE, evitando divisione per zero\n",
    "    mape = np.mean(np.abs((state_data['Forecasted Sales'] - state_data['Sales']) / state_data['Sales'])) * 100\n",
    "\n",
    "    metrics.append({\n",
    "        'State': state,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame con i risultati\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Mostra le metriche per ciascuno stato\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carica i dati\n",
    "df = pd.read_csv('Retailer Sales Data.csv')\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Pulisci i dati\n",
    "df_cleaned = df.dropna(subset=['State'])\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n",
    "# Crea le caratteristiche temporali\n",
    "monthly_sales['Month'] = monthly_sales['Year-Month'].dt.month\n",
    "monthly_sales['Year'] = monthly_sales['Year-Month'].dt.year\n",
    "\n",
    "# Creazione delle caratteristiche lag\n",
    "def create_lag_features(df, lags):\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df['Sales'].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Definisci i lag che vuoi utilizzare\n",
    "lags = [1, 2, 3, 6, 12, 18, 24 ,32]\n",
    "monthly_sales = create_lag_features(monthly_sales, lags)\n",
    "monthly_sales = monthly_sales.dropna()\n",
    "\n",
    "# Dividi i dati in addestramento e test\n",
    "X = monthly_sales.drop(['Year-Month', 'Sales'], axis=1)\n",
    "y = monthly_sales['Sales']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Crea e addestra il modello XGBoost\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=500, learning_rate=0.1, max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fai previsioni\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcola le metriche di errore\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred)\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape_xgb = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "# Stampa delle metriche di errore\n",
    "print(f'Mean Absolute Error (MAE) - XGBoost: {mae_xgb}')\n",
    "print(f'Root Mean Squared Error (RMSE) - XGBoost: {rmse_xgb}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - XGBoost: {mape_xgb}%')\n",
    "\n",
    "# Previsione per il 2018\n",
    "forecast_features = X[X.index >= monthly_sales[monthly_sales['Year-Month'] == '2017-12-01'].index[-1]]\n",
    "forecast_predictions = model.predict(forecast_features)\n",
    "\n",
    "# Creazione di un DataFrame con le previsioni aggregate\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Year-Month': pd.date_range(start='2018-01-01', periods=len(forecast_predictions), freq='MS'),\n",
    "    'Forecasted Sales': forecast_predictions\n",
    "})\n",
    "\n",
    "# Aggregazione delle vendite a livello 'year-month-state' per calcolare le proporzioni storiche\n",
    "statewise_monthly_sales = df_cleaned.groupby(['Year-Month', 'State'])['Sales'].sum().reset_index()\n",
    "\n",
    "# Calcolo della proporzione delle vendite per stato rispetto al totale mensile\n",
    "total_monthly_sales = statewise_monthly_sales.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "statewise_monthly_sales = pd.merge(statewise_monthly_sales, total_monthly_sales, on='Year-Month', suffixes=('', '_Total'))\n",
    "statewise_monthly_sales['Sales_Proportion'] = statewise_monthly_sales['Sales'] / statewise_monthly_sales['Sales_Total']\n",
    "\n",
    "# Usare l'ultimo mese disponibile per calcolare le proporzioni di disaggregazione\n",
    "last_known_month = statewise_monthly_sales[statewise_monthly_sales['Year-Month'] == statewise_monthly_sales['Year-Month'].max()]\n",
    "\n",
    "# Disaggregare le previsioni basandosi sulle proporzioni dell'ultimo mese disponibile\n",
    "disaggregated_forecast = []\n",
    "\n",
    "for _, forecast_row in forecast_df.iterrows():\n",
    "    forecast_month = forecast_row['Year-Month'].to_period('M')  # Assicurati che questo sia un Period\n",
    "    forecast_value = forecast_row['Forecasted Sales']\n",
    "    \n",
    "    # Applica le proporzioni storiche di ciascuno stato\n",
    "    for _, proportion_row in last_known_month.iterrows():\n",
    "        state = proportion_row['State']\n",
    "        proportion = proportion_row['Sales_Proportion']\n",
    "        state_forecast = forecast_value * proportion\n",
    "        \n",
    "        disaggregated_forecast.append({\n",
    "            'Year-Month': forecast_month,\n",
    "            'State': state,\n",
    "            'Forecasted Sales': state_forecast\n",
    "        })\n",
    "\n",
    "# Converti le previsioni disaggregate in un DataFrame\n",
    "disaggregated_forecast_df = pd.DataFrame(disaggregated_forecast)\n",
    "\n",
    "# Mostra il risultato delle previsioni disaggregate\n",
    "print(disaggregated_forecast_df.head())\n",
    "\n",
    "### VALUTAZIONE A LIVELLO DI STATO ###\n",
    "# Unisci i dati reali con le previsioni\n",
    "merged_df = pd.merge(\n",
    "    disaggregated_forecast_df,\n",
    "    statewise_monthly_sales[statewise_monthly_sales['Year-Month'] >= '2018-01-01'],\n",
    "    on=['Year-Month', 'State'],\n",
    "    how='left',\n",
    "    suffixes=('_Forecast', '_Actual')\n",
    ")\n",
    "\n",
    "# Calcola le metriche per ciascuno stato\n",
    "metrics = []\n",
    "\n",
    "# Itera attraverso ciascuno stato\n",
    "for state in merged_df['State'].unique():\n",
    "    state_data = merged_df[merged_df['State'] == state]\n",
    "    \n",
    "    # Calcola MAE\n",
    "    mae = np.mean(np.abs(state_data['Forecasted Sales'] - state_data['Sales']))\n",
    "    \n",
    "    # Calcola RMSE\n",
    "    rmse = np.sqrt(np.mean((state_data['Forecasted Sales'] - state_data['Sales']) ** 2))\n",
    "    \n",
    "    # Calcola MAPE, evitando divisione per zero\n",
    "    mape = np.mean(np.abs((state_data['Forecasted Sales'] - state_data['Sales']) / state_data['Sales'])) * 100\n",
    "\n",
    "    metrics.append({\n",
    "        'State': state,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame con i risultati\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Mostra le metriche per ciascuno stato\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definisci i parametri da ottimizzare\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Crea il modello XGBoost\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Crea la ricerca a griglia\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Esegui la ricerca\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Stampa i migliori parametri\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Utilizza il miglior modello per fare previsioni\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcola le metriche di errore\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred)\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape_xgb = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "# Stampa delle metriche di errore\n",
    "print(f'Mean Absolute Error (MAE) - XGBoost: {mae_xgb}')\n",
    "print(f'Root Mean Squared Error (RMSE) - XGBoost: {rmse_xgb}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - XGBoost: {mape_xgb}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST E SARIMA ESAMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/t3n4ptk97wl0rt09z81znxsw0000gn/T/ipykernel_73105/3555765479.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) - XGBoost: 24354.9064359375\n",
      "Root Mean Squared Error (RMSE) - XGBoost: 26499.69355890782\n",
      "Mean Absolute Percentage Error (MAPE) - XGBoost: 29.34054250381753%\n",
      "  Year-Month       State  Forecasted Sales\n",
      "0    2018-01     Alabama        987.958757\n",
      "1    2018-01     Arizona       1849.510452\n",
      "2    2018-01    Arkansas       1582.931136\n",
      "3    2018-01  California      19326.278731\n",
      "4    2018-01    Colorado       2875.997285\n",
      "             State          MAE         RMSE         MAPE\n",
      "0          Alabama   452.837226   524.766758  1868.677626\n",
      "1          Arizona   569.977283   868.436167   215.198148\n",
      "2         Arkansas   460.662265   578.097635  3891.599370\n",
      "3       California  4047.317459  5718.663283    68.528678\n",
      "4         Colorado  1157.663144  1351.195701          inf\n",
      "5      Connecticut   513.000043   635.201500  1136.552192\n",
      "6          Florida  1346.317254  1910.185725   114.079633\n",
      "7            Idaho   293.698219   430.951265    69.247428\n",
      "8         Illinois   961.945415  1193.982012    90.822414\n",
      "9          Indiana  1237.445521  1708.217129    88.949937\n",
      "10            Iowa   105.931362   150.137354    47.512775\n",
      "11        Kentucky  1156.998330  1361.228748   196.945456\n",
      "12       Louisiana   403.343664   505.478629   689.367783\n",
      "13   Massachusetts  1163.862560  1516.367380  3791.416360\n",
      "14        Michigan  1571.501174  2121.264003   506.536002\n",
      "15       Minnesota   368.794770   510.129294   210.527040\n",
      "16     Mississippi   414.496189   470.537349  1090.193466\n",
      "17        Missouri  1133.848645  1669.245651   126.714324\n",
      "18        Nebraska   315.279747   365.640628  1094.735794\n",
      "19      New Jersey   756.083800   980.361667  1354.840805\n",
      "20      New Mexico   176.383192   260.460849    46.047887\n",
      "21        New York  5233.112501  7702.856775   165.044979\n",
      "22  North Carolina  1662.027163  3734.987840    80.349044\n",
      "23    North Dakota   440.674688   623.152939    49.562153\n",
      "24            Ohio   982.483022  1379.359411   201.552660\n",
      "25        Oklahoma   470.921089   856.696746    80.434965\n",
      "26    Pennsylvania  1934.702895  3045.254946    48.445524\n",
      "27    Rhode Island   564.962779   734.531597   514.723144\n",
      "28  South Carolina   248.320366   359.095224    63.365627\n",
      "29       Tennessee  1115.502370  1442.943045  1356.287393\n",
      "30           Texas  1920.970606  2760.383047    58.392166\n",
      "31         Vermont   195.250439   275.727438    30.736152\n",
      "32        Virginia   704.914654   856.848282  3292.717301\n",
      "33      Washington  3415.324205  5558.163451   134.420752\n",
      "34       Wisconsin  1007.777373  1169.461584  7682.163948\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carica i dati\n",
    "df = pd.read_csv('Retailer Sales Data.csv')\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Pulisci i dati\n",
    "df_cleaned = df.dropna(subset=['State'])\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n",
    "# Crea le caratteristiche temporali\n",
    "monthly_sales['Month'] = monthly_sales['Year-Month'].dt.month\n",
    "monthly_sales['Year'] = monthly_sales['Year-Month'].dt.year\n",
    "\n",
    "# Creazione delle caratteristiche lag\n",
    "def create_lag_features(df, lags):\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df['Sales'].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Definisci i lag che vuoi utilizzare\n",
    "lags = [1, 2, 3, 6, 12, 18, 24 ,32]\n",
    "monthly_sales = create_lag_features(monthly_sales, lags)\n",
    "monthly_sales = monthly_sales.dropna()\n",
    "\n",
    "# Dividi i dati in addestramento e test\n",
    "X = monthly_sales.drop(['Year-Month', 'Sales'], axis=1)\n",
    "y = monthly_sales['Sales']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Crea e addestra il modello XGBoost\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=500, learning_rate=0.1, max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fai previsioni\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcola le metriche di errore\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred)\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape_xgb = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "# Stampa delle metriche di errore\n",
    "print(f'Mean Absolute Error (MAE) - XGBoost: {mae_xgb}')\n",
    "print(f'Root Mean Squared Error (RMSE) - XGBoost: {rmse_xgb}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - XGBoost: {mape_xgb}%')\n",
    "\n",
    "# Previsione per il 2018\n",
    "forecast_features = X[X.index >= monthly_sales[monthly_sales['Year-Month'] == '2017-12-01'].index[-1]]\n",
    "forecast_predictions = model.predict(forecast_features)\n",
    "\n",
    "# Creazione di un DataFrame con le previsioni aggregate\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Year-Month': pd.date_range(start='2018-01-01', periods=len(forecast_predictions), freq='MS'),\n",
    "    'Forecasted Sales': forecast_predictions\n",
    "})\n",
    "\n",
    "# Aggregazione delle vendite a livello 'year-month-state' per calcolare le proporzioni storiche\n",
    "statewise_monthly_sales = df_cleaned.groupby(['Year-Month', 'State'])['Sales'].sum().reset_index()\n",
    "\n",
    "# Calcolo della proporzione delle vendite per stato rispetto al totale mensile\n",
    "total_monthly_sales = statewise_monthly_sales.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "statewise_monthly_sales = pd.merge(statewise_monthly_sales, total_monthly_sales, on='Year-Month', suffixes=('', '_Total'))\n",
    "statewise_monthly_sales['Sales_Proportion'] = statewise_monthly_sales['Sales'] / statewise_monthly_sales['Sales_Total']\n",
    "\n",
    "# Usare l'ultimo mese disponibile per calcolare le proporzioni di disaggregazione\n",
    "last_known_month = statewise_monthly_sales[statewise_monthly_sales['Year-Month'] == statewise_monthly_sales['Year-Month'].max()]\n",
    "\n",
    "# Disaggregare le previsioni basandosi sulle proporzioni dell'ultimo mese disponibile\n",
    "disaggregated_forecast = []\n",
    "\n",
    "for _, forecast_row in forecast_df.iterrows():\n",
    "    forecast_month = forecast_row['Year-Month'].to_period('M')  # Assicurati che questo sia un Period\n",
    "    forecast_value = forecast_row['Forecasted Sales']\n",
    "    \n",
    "    # Applica le proporzioni storiche di ciascuno stato\n",
    "    for _, proportion_row in last_known_month.iterrows():\n",
    "        state = proportion_row['State']\n",
    "        proportion = proportion_row['Sales_Proportion']\n",
    "        state_forecast = forecast_value * proportion\n",
    "        \n",
    "        disaggregated_forecast.append({\n",
    "            'Year-Month': forecast_month,\n",
    "            'State': state,\n",
    "            'Forecasted Sales': state_forecast\n",
    "        })\n",
    "\n",
    "# Converti le previsioni disaggregate in un DataFrame\n",
    "disaggregated_forecast_df = pd.DataFrame(disaggregated_forecast)\n",
    "\n",
    "# Mostra il risultato delle previsioni disaggregate\n",
    "print(disaggregated_forecast_df.head())\n",
    "\n",
    "### VALUTAZIONE A LIVELLO DI STATO ###\n",
    "# Unisci i dati reali con le previsioni\n",
    "merged_df = pd.merge(\n",
    "    disaggregated_forecast_df,\n",
    "    statewise_monthly_sales[statewise_monthly_sales['Year-Month'] >= '2018-01-01'],\n",
    "    on=['Year-Month', 'State'],\n",
    "    how='left',\n",
    "    suffixes=('_Forecast', '_Actual')\n",
    ")\n",
    "\n",
    "# Calcola le metriche per ciascuno stato\n",
    "metrics = []\n",
    "\n",
    "# Itera attraverso ciascuno stato\n",
    "for state in merged_df['State'].unique():\n",
    "    state_data = merged_df[merged_df['State'] == state]\n",
    "    \n",
    "    # Calcola MAE\n",
    "    mae = np.mean(np.abs(state_data['Forecasted Sales'] - state_data['Sales']))\n",
    "    \n",
    "    # Calcola RMSE\n",
    "    rmse = np.sqrt(np.mean((state_data['Forecasted Sales'] - state_data['Sales']) ** 2))\n",
    "    \n",
    "    # Calcola MAPE, evitando divisione per zero\n",
    "    mape = np.mean(np.abs((state_data['Forecasted Sales'] - state_data['Sales']) / state_data['Sales'])) * 100\n",
    "\n",
    "    metrics.append({\n",
    "        'State': state,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame con i risultati\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Mostra le metriche per ciascuno stato\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.86602D+00    |proj g|=  1.06284D-01\n",
      "\n",
      "At iterate    5    f=  4.80539D+00    |proj g|=  5.10734D-02\n",
      "\n",
      "At iterate   10    f=  4.79964D+00    |proj g|=  2.96883D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     14     21      1     0     0   4.781D-06   4.800D+00\n",
      "  F =   4.7996226527635519     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/t3n4ptk97wl0rt09z81znxsw0000gn/T/ipykernel_73105/717150377.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
      "/Users/elenaabcc/miniconda3/envs/tensorflow/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/elenaabcc/miniconda3/envs/tensorflow/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/elenaabcc/miniconda3/envs/tensorflow/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      " This problem is unconstrained.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Carica i dati e converte la colonna 'Order Date' in datetime\n",
    "df = pd.read_csv('Retailer Sales Data.csv')\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Pulisci i dati\n",
    "df_cleaned = df.dropna(subset=['State'])\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n",
    "# Dividi i dati per l'addestramento di SARIMA (usiamo solo le vendite aggregate)\n",
    "train_data = monthly_sales.set_index('Year-Month')\n",
    "\n",
    "# Impostare il modello SARIMA\n",
    "sarima_model = SARIMAX(train_data['Sales'], \n",
    "                       order=(1,1,1), \n",
    "                       seasonal_order=(1,1,1,12), \n",
    "                       enforce_stationarity=False, \n",
    "                       enforce_invertibility=False)\n",
    "\n",
    "# Adattare il modello SARIMA\n",
    "sarima_results = sarima_model.fit()\n",
    "\n",
    "# Fai previsioni con SARIMA\n",
    "sarima_predictions = sarima_results.get_forecast(steps=len(train_data)).predicted_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsioni con XGBoost già implementato in precedenza\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Previsioni con XGBoost\n",
    "xgb_predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se SARIMA ha più previsioni del necessario, ritagliamo quelle corrispondenti\n",
    "sarima_predictions_aligned = sarima_predictions[-len(xgb_predictions):]  # Adatta la lunghezza\n",
    "ensemble_predictions = 0.5 * sarima_predictions_aligned + 0.5 * xgb_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo MAPE evitando divisioni per zero\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Aggiungi un controllo per evitare divisione per zero\n",
    "    non_zero_mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "    return mape\n",
    "\n",
    "# Calcolo MAPE per il modello ensemble\n",
    "mape_ensemble = calculate_mape(y_test, ensemble_predictions)\n",
    "\n",
    "# Calcola le metriche di errore per l'ensembling\n",
    "mae_ensemble = mean_absolute_error(y_test, ensemble_predictions)\n",
    "rmse_ensemble = mean_squared_error(y_test, ensemble_predictions, squared=False)\n",
    "\n",
    "# Stampa le metriche\n",
    "print(f'Mean Absolute Error (MAE) - Ensemble: {mae_ensemble}')\n",
    "print(f'Root Mean Squared Error (RMSE) - Ensemble: {rmse_ensemble}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - Ensemble: {mape_ensemble}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             State          MAE         RMSE  MAPE\n",
      "0          Alabama   452.837226   524.766758   NaN\n",
      "1          Arizona   569.977283   868.436167   NaN\n",
      "2         Arkansas   460.662265   578.097635   NaN\n",
      "3       California  4047.317459  5718.663283   NaN\n",
      "4         Colorado  1157.663144  1351.195701   NaN\n",
      "5      Connecticut   513.000043   635.201500   NaN\n",
      "6          Florida  1346.317254  1910.185725   NaN\n",
      "7            Idaho   293.698219   430.951265   NaN\n",
      "8         Illinois   961.945415  1193.982012   NaN\n",
      "9          Indiana  1237.445521  1708.217129   NaN\n",
      "10            Iowa   105.931362   150.137354   NaN\n",
      "11        Kentucky  1156.998330  1361.228748   NaN\n",
      "12       Louisiana   403.343664   505.478629   NaN\n",
      "13   Massachusetts  1163.862560  1516.367380   NaN\n",
      "14        Michigan  1571.501174  2121.264003   NaN\n",
      "15       Minnesota   368.794770   510.129294   NaN\n",
      "16     Mississippi   414.496189   470.537349   NaN\n",
      "17        Missouri  1133.848645  1669.245651   NaN\n",
      "18        Nebraska   315.279747   365.640628   NaN\n",
      "19      New Jersey   756.083800   980.361667   NaN\n",
      "20      New Mexico   176.383192   260.460849   NaN\n",
      "21        New York  5233.112501  7702.856775   NaN\n",
      "22  North Carolina  1662.027163  3734.987840   NaN\n",
      "23    North Dakota   440.674688   623.152939   NaN\n",
      "24            Ohio   982.483022  1379.359411   NaN\n",
      "25        Oklahoma   470.921089   856.696746   NaN\n",
      "26    Pennsylvania  1934.702895  3045.254946   NaN\n",
      "27    Rhode Island   564.962779   734.531597   NaN\n",
      "28  South Carolina   248.320366   359.095224   NaN\n",
      "29       Tennessee  1115.502370  1442.943045   NaN\n",
      "30           Texas  1920.970606  2760.383047   NaN\n",
      "31         Vermont   195.250439   275.727438   NaN\n",
      "32        Virginia   704.914654   856.848282   NaN\n",
      "33      Washington  3415.324205  5558.163451   NaN\n",
      "34       Wisconsin  1007.777373  1169.461584   NaN\n"
     ]
    }
   ],
   "source": [
    "# Unisci le previsioni ensemble con i dati reali\n",
    "merged_df = pd.merge(\n",
    "    disaggregated_forecast_df,  # DataFrame con previsioni disaggregate\n",
    "    statewise_monthly_sales[statewise_monthly_sales['Year-Month'] >= '2018-01-01'],  # Dati reali\n",
    "    on=['Year-Month', 'State'],\n",
    "    how='left',\n",
    "    suffixes=('_Forecast', '_Actual')\n",
    ")\n",
    "\n",
    "# Itera attraverso ciascuno stato e calcola le metriche\n",
    "metrics = []\n",
    "for state in merged_df['State'].unique():\n",
    "    state_data = merged_df[merged_df['State'] == state]\n",
    "    \n",
    "    # MAE\n",
    "    mae = np.mean(np.abs(state_data['Forecasted Sales'] - state_data['Sales']))\n",
    "    \n",
    "    # RMSE\n",
    "    rmse = np.sqrt(np.mean((state_data['Forecasted Sales'] - state_data['Sales']) ** 2))\n",
    "    \n",
    "    # Calcola MAPE, evitando divisione per zero\n",
    "    def calculate_mape(y_true, y_pred):\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        non_zero_mask = y_true != 0\n",
    "        mape = np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "        return mape\n",
    "    \n",
    "    mape = calculate_mape(state_data['Sales'], state_data['Forecasted Sales'])\n",
    "\n",
    "    # Salva i risultati in una lista\n",
    "    metrics.append({\n",
    "        'State': state,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame con i risultati delle metriche per stato\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Mostra i risultati\n",
    "print(metrics_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
