{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retailer Sales Data Forecasting\n",
    "\n",
    "This dataset contains the daily sales data of a US retailer.  \n",
    "Your objective is to forecast the total sales for each State over the next 12 months, using the historical data provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Top-Down Approach\n",
    "\n",
    "1. **Aggregate Sales:**  \n",
    "   Combine the sales data to create total sales at the `year-month` level, using the `Order Date` as the time variable for aggregation.\n",
    "\n",
    "\n",
    "2. **Train a Model:**  \n",
    "   Using the aggregated `year-month` data, train a model to forecast the total sales for the next 12 months.  \n",
    "   *(The choice of model is up to you.)*\n",
    "\n",
    "3. **Disaggregate Predictions:**  \n",
    "   Split the predicted sales from the `year-month` level back to the `year-month-State` level.  \n",
    "   *(The splitting strategy is up to you.)*\n",
    "\n",
    "4. **Evaluate Accuracy:**  \n",
    "   Assess the forecast accuracy at both the `year-month` and `year-month-State` levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Alternative Approach\n",
    "\n",
    "- Implement a different approach to forecast the next 12 months of sales at the `year-month-State` level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/t3n4ptk97wl0rt09z81znxsw0000gn/T/ipykernel_69981/219175578.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Retailer Sales Data.csv')\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\n",
    "\n",
    "\n",
    "# Drop rows where 'State' is missing (we need state-level forecasts)\n",
    "df_cleaned = df.dropna(subset=['State'])\n",
    "\n",
    "# Create 'Year-Month' column from 'Order Date'\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "\n",
    "# Aggregate sales at the 'Year-Month' level\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "\n",
    "# Convert 'Year-Month' back to a datetime format for consistency\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for time series forecasting\n",
    "monthly_sales.set_index('Year-Month', inplace=True)\n",
    "\n",
    "# Apply Exponential Smoothing model (Holt-Winters method)\n",
    "model = ExponentialSmoothing(monthly_sales['Sales'], trend='add', seasonal=None, seasonal_periods=12)\n",
    "hw_model = model.fit()\n",
    "\n",
    "# Forecast the next 12 months\n",
    "forecast_periods = 12\n",
    "forecast = hw_model.forecast(steps=forecast_periods)\n",
    "\n",
    "# Generate future dates for the forecast\n",
    "future_dates = pd.date_range(start=monthly_sales.index[-1] + pd.DateOffset(months=1), periods=forecast_periods, freq='MS')\n",
    "\n",
    "# Combine forecast with future dates\n",
    "forecast_df = pd.DataFrame({'Year-Month': future_dates, 'Forecasted Sales': forecast})\n",
    "\n",
    "# Show the forecasted results\n",
    "forecast_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate historical state-wise proportions\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "\n",
    "# Aggregate sales by 'Year-Month' and 'State'\n",
    "statewise_monthly_sales = df_cleaned.groupby(['Year-Month', 'State'])['Sales'].sum().reset_index()\n",
    "\n",
    "# Calculate state-wise sales as a proportion of the total sales in that month\n",
    "statewise_monthly_sales['Year-Month'] = statewise_monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "total_monthly_sales = statewise_monthly_sales.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "\n",
    "# Merge the total monthly sales with the state-wise sales\n",
    "statewise_monthly_sales = pd.merge(statewise_monthly_sales, total_monthly_sales, on='Year-Month', suffixes=('', '_Total'))\n",
    "\n",
    "# Calculate the proportion of state sales\n",
    "statewise_monthly_sales['Sales_Proportion'] = statewise_monthly_sales['Sales'] / statewise_monthly_sales['Sales_Total']\n",
    "\n",
    "# Use the last available month's proportions for disaggregation of the forecast\n",
    "last_known_month = statewise_monthly_sales[statewise_monthly_sales['Year-Month'] == statewise_monthly_sales['Year-Month'].max()]\n",
    "\n",
    "# Disaggregate the forecast based on the proportions from the last known month\n",
    "disaggregated_forecast = []\n",
    "\n",
    "for _, forecast_row in forecast_df.iterrows():\n",
    "    forecast_month = forecast_row['Year-Month']\n",
    "    forecast_value = forecast_row['Forecasted Sales']\n",
    "    \n",
    "    # Apply the state-wise proportions from the last available month\n",
    "    for _, proportion_row in last_known_month.iterrows():\n",
    "        state = proportion_row['State']\n",
    "        proportion = proportion_row['Sales_Proportion']\n",
    "        state_forecast = forecast_value * proportion\n",
    "        \n",
    "        disaggregated_forecast.append({\n",
    "            'Year-Month': forecast_month,\n",
    "            'State': state,\n",
    "            'Forecasted Sales': state_forecast\n",
    "        })\n",
    "\n",
    "# Convert disaggregated forecast to DataFrame\n",
    "disaggregated_forecast_df = pd.DataFrame(disaggregated_forecast)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Assuming 'monthly_sales' is your complete historical dataset\n",
    "# Split data into training and testing sets (e.g., last 12 months for testing)\n",
    "train_data = monthly_sales[:-12]\n",
    "test_data = monthly_sales[-12:]\n",
    "\n",
    "# Train the model on the training data\n",
    "model = ExponentialSmoothing(train_data['Sales'], trend='add', seasonal=None, seasonal_periods=12)\n",
    "hw_model = model.fit()\n",
    "\n",
    "# Forecast the same period as the test data\n",
    "predictions = hw_model.forecast(steps=12)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = mean_absolute_error(test_data['Sales'], predictions)\n",
    "rmse = mean_squared_error(test_data['Sales'], predictions, squared=False)\n",
    "mape = np.mean(np.abs((test_data['Sales'] - predictions) / test_data['Sales'])) * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) - SARIMA: 15411.558676616303\n",
      "Root Mean Squared Error (RMSE) - SARIMA: 18005.217400851787\n",
      "Mean Absolute Percentage Error (MAPE) - SARIMA: 42.68170147743031%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenaabcc/miniconda3/envs/tensorflow/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Train-test split (usiamo gli ultimi 12 mesi per il test)\n",
    "train_data = monthly_sales[:-12]\n",
    "test_data = monthly_sales[-12:]\n",
    "\n",
    "# Addestramento del modello SARIMA con i parametri di esempio (puoi regolarli in base alla situazione)\n",
    "sarima_model = SARIMAX(train_data['Sales'], \n",
    "                       order=(1, 1, 1),  # Parametri ARIMA(p, d, q)\n",
    "                       seasonal_order=(1, 1, 1, 12))  # Parametri stagionali (P, D, Q, S) con stagionalitÃ  annuale\n",
    "\n",
    "sarima_fit = sarima_model.fit(disp=False)\n",
    "\n",
    "# Fare previsioni per i 12 mesi del test\n",
    "sarima_predictions = sarima_fit.forecast(steps=12)\n",
    "\n",
    "# Calcolare le metriche di errore\n",
    "mae_sarima = mean_absolute_error(test_data['Sales'], sarima_predictions)\n",
    "rmse_sarima = mean_squared_error(test_data['Sales'], sarima_predictions, squared=False)\n",
    "mape_sarima = np.mean(np.abs((test_data['Sales'] - sarima_predictions) / test_data['Sales'])) * 100\n",
    "\n",
    "# Stampare i risultati\n",
    "print(f'Mean Absolute Error (MAE) - SARIMA: {mae_sarima}')\n",
    "print(f'Root Mean Squared Error (RMSE) - SARIMA: {rmse_sarima}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - SARIMA: {mape_sarima}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01\n",
      "2018-12\n"
     ]
    }
   ],
   "source": [
    "# print il min e max df_cleaned['Year-Month']\n",
    "print(df_cleaned['Year-Month'].min())\n",
    "print(df_cleaned['Year-Month'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) - SARIMA: 15411.558676616303\n",
      "Root Mean Squared Error (RMSE) - SARIMA: 18005.217400851787\n",
      "Mean Absolute Percentage Error (MAPE) - SARIMA: 42.68170147743031%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/t3n4ptk97wl0rt09z81znxsw0000gn/T/ipykernel_69981/1580908429.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
      "/Users/elenaabcc/miniconda3/envs/tensorflow/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Supponiamo che 'df_cleaned' sia il dataframe pulito e pronto all'uso\n",
    "# Aggregazione delle vendite a livello 'year-month'\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n",
    "# Train-test split (usiamo gli ultimi 12 mesi per il test)\n",
    "train_data = monthly_sales[:-12]\n",
    "test_data = monthly_sales[-12:]\n",
    "\n",
    "# Addestramento del modello SARIMA\n",
    "sarima_model = SARIMAX(train_data['Sales'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "sarima_fit = sarima_model.fit(disp=False)\n",
    "\n",
    "# Fare previsioni per i prossimi 12 mesi\n",
    "sarima_predictions = sarima_fit.forecast(steps=12)\n",
    "\n",
    "# Calcolo delle metriche di errore a livello aggregato\n",
    "mae_sarima = mean_absolute_error(test_data['Sales'], sarima_predictions)\n",
    "rmse_sarima = mean_squared_error(test_data['Sales'], sarima_predictions, squared=False)\n",
    "mape_sarima = np.mean(np.abs((test_data['Sales'] - sarima_predictions) / test_data['Sales'])) * 100\n",
    "\n",
    "# Stampa delle metriche di errore\n",
    "print(f'Mean Absolute Error (MAE) - SARIMA: {mae_sarima}')\n",
    "print(f'Root Mean Squared Error (RMSE) - SARIMA: {rmse_sarima}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - SARIMA: {mape_sarima}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Year-Month       State  Forecasted Sales\n",
      "0    2019-01     Alabama        556.743317\n",
      "1    2019-01     Arizona       1042.252602\n",
      "2    2019-01    Arkansas        892.027452\n",
      "3    2019-01  California      10890.916715\n",
      "4    2019-01    Colorado       1620.707604\n",
      "    Year-Month                 State     Sales  Sales_Total  Sales_Proportion\n",
      "869    2018-01               Alabama    56.370    35688.064          0.001580\n",
      "870    2018-01               Arizona   100.922    35688.064          0.002828\n",
      "871    2018-01            California  5022.232    35688.064          0.140726\n",
      "872    2018-01              Colorado   169.064    35688.064          0.004737\n",
      "873    2018-01  District of Columbia    77.760    35688.064          0.002179\n"
     ]
    }
   ],
   "source": [
    "# Creazione di un dataframe con le previsioni e le date future\n",
    "future_dates = pd.date_range(start=monthly_sales['Year-Month'].max() + pd.DateOffset(months=1), periods=12, freq='MS')\n",
    "forecast_df = pd.DataFrame({'Year-Month': future_dates, 'Forecasted Sales': sarima_predictions})\n",
    "\n",
    "### DISAGGREGAZIONE DELLE PREVISIONI A LIVELLO DI STATO ###\n",
    "\n",
    "# Aggregazione delle vendite a livello 'year-month-state' per calcolare le proporzioni storiche\n",
    "statewise_monthly_sales = df_cleaned.groupby(['Year-Month', 'State'])['Sales'].sum().reset_index()\n",
    "\n",
    "# Assicurati che la colonna 'Year-Month' sia di tipo Period\n",
    "#statewise_monthly_sales['Year-Month'] = statewise_monthly_sales['Year-Month'].dt.to_period('M')\n",
    "\n",
    "# Calcolo della proporzione delle vendite per stato rispetto al totale mensile\n",
    "total_monthly_sales = statewise_monthly_sales.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "statewise_monthly_sales = pd.merge(statewise_monthly_sales, total_monthly_sales, on='Year-Month', suffixes=('', '_Total'))\n",
    "statewise_monthly_sales['Sales_Proportion'] = statewise_monthly_sales['Sales'] / statewise_monthly_sales['Sales_Total']\n",
    "\n",
    "# Usare l'ultimo mese disponibile per calcolare le proporzioni di disaggregazione\n",
    "last_known_month = statewise_monthly_sales[statewise_monthly_sales['Year-Month'] == statewise_monthly_sales['Year-Month'].max()]\n",
    "\n",
    "# Disaggregare le previsioni basandosi sulle proporzioni dell'ultimo mese disponibile\n",
    "disaggregated_forecast = []\n",
    "\n",
    "for _, forecast_row in forecast_df.iterrows():\n",
    "    forecast_month = forecast_row['Year-Month'].to_period('M')  # Assicurati che questo sia un Period\n",
    "    forecast_value = forecast_row['Forecasted Sales']\n",
    "    \n",
    "    # Applica le proporzioni storiche di ciascuno stato\n",
    "    for _, proportion_row in last_known_month.iterrows():\n",
    "        state = proportion_row['State']\n",
    "        proportion = proportion_row['Sales_Proportion']\n",
    "        state_forecast = forecast_value * proportion\n",
    "        \n",
    "        disaggregated_forecast.append({\n",
    "            'Year-Month': forecast_month,\n",
    "            'State': state,\n",
    "            'Forecasted Sales': state_forecast\n",
    "        })\n",
    "\n",
    "# Converti le previsioni disaggregate in un dataframe\n",
    "disaggregated_forecast_df = pd.DataFrame(disaggregated_forecast)\n",
    "\n",
    "# Mostra il risultato delle previsioni disaggregate\n",
    "print(disaggregated_forecast_df.head())\n",
    "\n",
    "### VALUTAZIONE A LIVELLO DI STATO ###\n",
    "# Calcola la data minima nel periodo di test e convertila in Period\n",
    "test_data_min_date = pd.to_datetime(test_data['Year-Month'].min()).to_period('M')\n",
    "\n",
    "# Filtro sulle vendite effettive a livello di stato, a partire dalla data minima del periodo di test\n",
    "actual_state_sales = statewise_monthly_sales[statewise_monthly_sales['Year-Month'] >= test_data_min_date]\n",
    "\n",
    "# Mostra i risultati per verificare che il confronto avvenga correttamente\n",
    "print(actual_state_sales.head())\n",
    "\n",
    "# Calcola le metriche a livello di stato (se hai i dati effettivi da confrontare)\n",
    "# MAE, RMSE, e MAPE possono essere calcolati per ciascuno stato allo stesso modo delle previsioni mensili\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             State  MAE  RMSE  MAPE\n",
      "0          Alabama  NaN   NaN   NaN\n",
      "1          Arizona  NaN   NaN   NaN\n",
      "2         Arkansas  NaN   NaN   NaN\n",
      "3       California  NaN   NaN   NaN\n",
      "4         Colorado  NaN   NaN   NaN\n",
      "5      Connecticut  NaN   NaN   NaN\n",
      "6          Florida  NaN   NaN   NaN\n",
      "7            Idaho  NaN   NaN   NaN\n",
      "8         Illinois  NaN   NaN   NaN\n",
      "9          Indiana  NaN   NaN   NaN\n",
      "10            Iowa  NaN   NaN   NaN\n",
      "11        Kentucky  NaN   NaN   NaN\n",
      "12       Louisiana  NaN   NaN   NaN\n",
      "13   Massachusetts  NaN   NaN   NaN\n",
      "14        Michigan  NaN   NaN   NaN\n",
      "15       Minnesota  NaN   NaN   NaN\n",
      "16     Mississippi  NaN   NaN   NaN\n",
      "17        Missouri  NaN   NaN   NaN\n",
      "18        Nebraska  NaN   NaN   NaN\n",
      "19      New Jersey  NaN   NaN   NaN\n",
      "20      New Mexico  NaN   NaN   NaN\n",
      "21        New York  NaN   NaN   NaN\n",
      "22  North Carolina  NaN   NaN   NaN\n",
      "23    North Dakota  NaN   NaN   NaN\n",
      "24            Ohio  NaN   NaN   NaN\n",
      "25        Oklahoma  NaN   NaN   NaN\n",
      "26    Pennsylvania  NaN   NaN   NaN\n",
      "27    Rhode Island  NaN   NaN   NaN\n",
      "28  South Carolina  NaN   NaN   NaN\n",
      "29       Tennessee  NaN   NaN   NaN\n",
      "30           Texas  NaN   NaN   NaN\n",
      "31         Vermont  NaN   NaN   NaN\n",
      "32        Virginia  NaN   NaN   NaN\n",
      "33      Washington  NaN   NaN   NaN\n",
      "34       Wisconsin  NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) - SARIMA: 15411.558676616303\n",
      "Root Mean Squared Error (RMSE) - SARIMA: 18005.217400851787\n",
      "Mean Absolute Percentage Error (MAPE) - SARIMA: 42.68170147743031%\n",
      "  Year-Month       State  Forecasted Sales\n",
      "0    2018-01     Alabama        556.743317\n",
      "1    2018-01     Arizona       1042.252602\n",
      "2    2018-01    Arkansas        892.027452\n",
      "3    2018-01  California      10890.916715\n",
      "4    2018-01    Colorado       1620.707604\n",
      "             State          MAE         RMSE         MAPE\n",
      "0          Alabama   588.137995   611.306035  2508.086480\n",
      "1          Arizona   671.816038   748.746890   182.771597\n",
      "2         Arkansas   948.679864  1035.178320  6345.995669\n",
      "3       California  4181.289192  4789.261579    63.449909\n",
      "4         Colorado  1542.783821  1672.559593          inf\n",
      "5      Connecticut   783.493690   878.320336  1630.220402\n",
      "6          Florida  1281.215594  1708.241162   169.801122\n",
      "7            Idaho   289.610025   424.355606    74.166987\n",
      "8         Illinois  1463.194774  1791.332599   154.523410\n",
      "9          Indiana  1136.129598  1517.295605    92.597635\n",
      "10            Iowa   120.057566   165.725335    59.966336\n",
      "11        Kentucky  2156.703280  2361.040821   359.008513\n",
      "12       Louisiana   700.753997   885.892555   952.652068\n",
      "13   Massachusetts  1731.563951  1968.469459  3272.791916\n",
      "14        Michigan  2651.285302  3170.484940   745.951742\n",
      "15       Minnesota   599.908588   702.636733   369.333784\n",
      "16     Mississippi   556.025560   675.530906  1715.986099\n",
      "17        Missouri  1197.145097  1808.196153   144.769268\n",
      "18        Nebraska   545.757696   574.920688  1746.562227\n",
      "19      New Jersey   892.345062  1018.843038  1751.102652\n",
      "20      New Mexico   162.237061   231.240312    49.377598\n",
      "21        New York  4793.725313  6712.432835   149.260969\n",
      "22  North Carolina  1656.854996  3713.760957   145.155166\n",
      "23    North Dakota   437.084354   612.387032    62.946904\n",
      "24            Ohio   886.932448  1191.816143   222.147253\n",
      "25        Oklahoma   468.031667   854.717806    80.967024\n",
      "26    Pennsylvania  1714.004061  2773.083541    39.580350\n",
      "27    Rhode Island   833.716038   915.937191   623.792082\n",
      "28  South Carolina   239.694089   350.554825    63.421035\n",
      "29       Tennessee  1277.419185  1391.945614  4426.248588\n",
      "30           Texas  1553.465184  2151.726640    50.253434\n",
      "31         Vermont   278.405532   354.494228    53.445070\n",
      "32        Virginia  1091.248492  1202.846028  3474.265568\n",
      "33      Washington  2966.247548  4762.404786   130.672639\n",
      "34       Wisconsin  1080.850503  1178.033210  4692.267099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/t3n4ptk97wl0rt09z81znxsw0000gn/T/ipykernel_70287/1024365759.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
      "/var/folders/3c/t3n4ptk97wl0rt09z81znxsw0000gn/T/ipykernel_70287/1024365759.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
      "/Users/elenaabcc/miniconda3/envs/tensorflow/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Retailer Sales Data.csv')\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\n",
    "\n",
    "\n",
    "# Drop rows where 'State' is missing (we need state-level forecasts)\n",
    "df_cleaned = df.dropna(subset=['State'])\n",
    "\n",
    "# Create 'Year-Month' column from 'Order Date'\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "\n",
    "# Aggregate sales at the 'Year-Month' level\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "\n",
    "# Convert 'Year-Month' back to a datetime format for consistency\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n",
    "\n",
    "\n",
    "# Supponiamo che 'df_cleaned' sia il dataframe pulito e pronto all'uso\n",
    "# Aggregazione delle vendite a livello 'year-month'\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n",
    "# Impostiamo i dati di addestramento fino a dicembre 2017 e usiamo il 2018 per il test\n",
    "train_data = monthly_sales[monthly_sales['Year-Month'] < '2018-01-01']\n",
    "test_data = monthly_sales[monthly_sales['Year-Month'] >= '2018-01-01']\n",
    "\n",
    "# Addestramento del modello SARIMA\n",
    "sarima_model = SARIMAX(train_data['Sales'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "sarima_fit = sarima_model.fit(disp=False)\n",
    "\n",
    "# Fare previsioni per tutto il 2018 (12 mesi)\n",
    "sarima_predictions = sarima_fit.forecast(steps=len(test_data))\n",
    "\n",
    "# Calcolo delle metriche di errore a livello aggregato\n",
    "mae_sarima = mean_absolute_error(test_data['Sales'], sarima_predictions)\n",
    "rmse_sarima = mean_squared_error(test_data['Sales'], sarima_predictions, squared=False)\n",
    "mape_sarima = np.mean(np.abs((test_data['Sales'] - sarima_predictions) / test_data['Sales'])) * 100\n",
    "\n",
    "# Stampa delle metriche di errore\n",
    "print(f'Mean Absolute Error (MAE) - SARIMA: {mae_sarima}')\n",
    "print(f'Root Mean Squared Error (RMSE) - SARIMA: {rmse_sarima}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - SARIMA: {mape_sarima}%')\n",
    "\n",
    "# Creazione di un dataframe con le previsioni e le date future\n",
    "future_dates = pd.date_range(start=test_data['Year-Month'].min(), periods=len(test_data), freq='MS')\n",
    "forecast_df = pd.DataFrame({'Year-Month': future_dates, 'Forecasted Sales': sarima_predictions})\n",
    "\n",
    "### DISAGGREGAZIONE DELLE PREVISIONI A LIVELLO DI STATO ###\n",
    "\n",
    "# Aggregazione delle vendite a livello 'year-month-state' per calcolare le proporzioni storiche\n",
    "statewise_monthly_sales = df_cleaned.groupby(['Year-Month', 'State'])['Sales'].sum().reset_index()\n",
    "\n",
    "# Calcolo della proporzione delle vendite per stato rispetto al totale mensile\n",
    "total_monthly_sales = statewise_monthly_sales.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "statewise_monthly_sales = pd.merge(statewise_monthly_sales, total_monthly_sales, on='Year-Month', suffixes=('', '_Total'))\n",
    "statewise_monthly_sales['Sales_Proportion'] = statewise_monthly_sales['Sales'] / statewise_monthly_sales['Sales_Total']\n",
    "\n",
    "# Usare l'ultimo mese disponibile per calcolare le proporzioni di disaggregazione\n",
    "last_known_month = statewise_monthly_sales[statewise_monthly_sales['Year-Month'] == statewise_monthly_sales['Year-Month'].max()]\n",
    "\n",
    "# Disaggregare le previsioni basandosi sulle proporzioni dell'ultimo mese disponibile\n",
    "disaggregated_forecast = []\n",
    "\n",
    "for _, forecast_row in forecast_df.iterrows():\n",
    "    forecast_month = forecast_row['Year-Month'].to_period('M')  # Assicurati che questo sia un Period\n",
    "    forecast_value = forecast_row['Forecasted Sales']\n",
    "    \n",
    "    # Applica le proporzioni storiche di ciascuno stato\n",
    "    for _, proportion_row in last_known_month.iterrows():\n",
    "        state = proportion_row['State']\n",
    "        proportion = proportion_row['Sales_Proportion']\n",
    "        state_forecast = forecast_value * proportion\n",
    "        \n",
    "        disaggregated_forecast.append({\n",
    "            'Year-Month': forecast_month,\n",
    "            'State': state,\n",
    "            'Forecasted Sales': state_forecast\n",
    "        })\n",
    "\n",
    "# Converti le previsioni disaggregate in un dataframe\n",
    "disaggregated_forecast_df = pd.DataFrame(disaggregated_forecast)\n",
    "\n",
    "# Mostra il risultato delle previsioni disaggregate\n",
    "print(disaggregated_forecast_df.head())\n",
    "\n",
    "### VALUTAZIONE A LIVELLO DI STATO ###\n",
    "# Calcola le metriche a livello di stato (se hai i dati effettivi da confrontare)\n",
    "\n",
    "# Unisci i dati reali con le previsioni\n",
    "merged_df = pd.merge(\n",
    "    disaggregated_forecast_df,\n",
    "    statewise_monthly_sales[statewise_monthly_sales['Year-Month'] >= '2018-01-01'],\n",
    "    on=['Year-Month', 'State'],\n",
    "    how='left',\n",
    "    suffixes=('_Forecast', '_Actual')\n",
    ")\n",
    "\n",
    "# Calcola le metriche per ciascuno stato\n",
    "metrics = []\n",
    "\n",
    "# Itera attraverso ciascuno stato\n",
    "for state in merged_df['State'].unique():\n",
    "    state_data = merged_df[merged_df['State'] == state]\n",
    "    \n",
    "    # Calcola MAE\n",
    "    mae = np.mean(np.abs(state_data['Forecasted Sales'] - state_data['Sales']))\n",
    "    \n",
    "    # Calcola RMSE\n",
    "    rmse = np.sqrt(np.mean((state_data['Forecasted Sales'] - state_data['Sales']) ** 2))\n",
    "    \n",
    "    # Calcola MAPE, evitando divisione per zero\n",
    "    mape = np.mean(np.abs((state_data['Forecasted Sales'] - state_data['Sales']) / state_data['Sales'])) * 100\n",
    "\n",
    "    metrics.append({\n",
    "        'State': state,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame con i risultati\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Mostra le metriche per ciascuno stato\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) - XGBoost: 13046.314957031249\n",
      "Root Mean Squared Error (RMSE) - XGBoost: 15276.032036023355\n",
      "Mean Absolute Percentage Error (MAPE) - XGBoost: 20.835464866020455%\n",
      "  Year-Month       State  Forecasted Sales\n",
      "0    2018-01     Alabama        981.372572\n",
      "1    2018-01     Arizona       1837.180770\n",
      "2    2018-01    Arkansas       1572.378593\n",
      "3    2018-01  California      19197.440917\n",
      "4    2018-01    Colorado       2856.824572\n",
      "             State          MAE         RMSE         MAPE\n",
      "0          Alabama   545.626996   593.520702  2200.049375\n",
      "1          Arizona   575.811650   785.994849   213.870447\n",
      "2         Arkansas   651.660749   766.143386  5269.750397\n",
      "3       California  5307.368212  6334.815628    78.836852\n",
      "4         Colorado  1278.633876  1491.004237          inf\n",
      "5      Connecticut   521.819389   616.336101  1280.333970\n",
      "6          Florida  1320.118365  1839.507433   111.457969\n",
      "7            Idaho   295.512619   430.637117    75.604637\n",
      "8         Illinois  1168.874735  1492.048702   102.823121\n",
      "9          Indiana  1227.395676  1654.934557    89.952437\n",
      "10            Iowa   109.523075   150.518513    54.124967\n",
      "11        Kentucky  1119.362361  1420.154492   210.646447\n",
      "12       Louisiana   429.967855   516.169671   689.572348\n",
      "13   Massachusetts  1360.469452  1679.684586  3923.807332\n",
      "14        Michigan  1989.762586  2417.323312   551.337925\n",
      "15       Minnesota   497.478041   591.187587   261.359320\n",
      "16     Mississippi   520.556666   578.910009  1317.176141\n",
      "17        Missouri  1242.174533  1728.982427   147.051009\n",
      "18        Nebraska   348.762975   373.424756   881.775789\n",
      "19      New Jersey   835.274673  1022.186368  1162.447993\n",
      "20      New Mexico   189.567485   266.529851    56.397887\n",
      "21        New York  5075.131629  7295.971982   161.487713\n",
      "22  North Carolina  1662.556764  3722.361516    84.151040\n",
      "23    North Dakota   443.282636   622.938624    59.299037\n",
      "24            Ohio   984.545441  1348.509491   201.609050\n",
      "25        Oklahoma   471.189266   856.399450    82.020891\n",
      "26    Pennsylvania  1951.155844  3088.171126    48.026167\n",
      "27    Rhode Island   516.872964   602.050610   399.141452\n",
      "28  South Carolina   250.036048   363.815361    64.997367\n",
      "29       Tennessee  1072.293915  1351.260941  1362.602213\n",
      "30           Texas  1927.410394  2673.153482    60.324157\n",
      "31         Vermont   216.075000   278.374342    40.620377\n",
      "32        Virginia   825.636889   970.155353  3280.316372\n",
      "33      Washington  3495.122979  5442.569113   139.581612\n",
      "34       Wisconsin  1045.064627  1216.209706  7671.972283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/t3n4ptk97wl0rt09z81znxsw0000gn/T/ipykernel_70287/2200259195.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carica i dati\n",
    "df = pd.read_csv('Retailer Sales Data.csv')\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Pulisci i dati\n",
    "df_cleaned = df.dropna(subset=['State'])\n",
    "df_cleaned['Year-Month'] = df_cleaned['Order Date'].dt.to_period('M')\n",
    "monthly_sales = df_cleaned.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "monthly_sales['Year-Month'] = monthly_sales['Year-Month'].dt.to_timestamp()\n",
    "\n",
    "# Crea le caratteristiche temporali\n",
    "monthly_sales['Month'] = monthly_sales['Year-Month'].dt.month\n",
    "monthly_sales['Year'] = monthly_sales['Year-Month'].dt.year\n",
    "\n",
    "# Creazione delle caratteristiche lag\n",
    "def create_lag_features(df, lags):\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df['Sales'].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Definisci i lag che vuoi utilizzare\n",
    "lags = [1, 2, 3, 6, 12]\n",
    "monthly_sales = create_lag_features(monthly_sales, lags)\n",
    "monthly_sales = monthly_sales.dropna()\n",
    "\n",
    "# Dividi i dati in addestramento e test\n",
    "X = monthly_sales.drop(['Year-Month', 'Sales'], axis=1)\n",
    "y = monthly_sales['Sales']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Crea e addestra il modello XGBoost\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fai previsioni\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcola le metriche di errore\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred)\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape_xgb = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "# Stampa delle metriche di errore\n",
    "print(f'Mean Absolute Error (MAE) - XGBoost: {mae_xgb}')\n",
    "print(f'Root Mean Squared Error (RMSE) - XGBoost: {rmse_xgb}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - XGBoost: {mape_xgb}%')\n",
    "\n",
    "# Previsione per il 2018\n",
    "forecast_features = X[X.index >= monthly_sales[monthly_sales['Year-Month'] == '2017-12-01'].index[-1]]\n",
    "forecast_predictions = model.predict(forecast_features)\n",
    "\n",
    "# Creazione di un DataFrame con le previsioni aggregate\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Year-Month': pd.date_range(start='2018-01-01', periods=len(forecast_predictions), freq='MS'),\n",
    "    'Forecasted Sales': forecast_predictions\n",
    "})\n",
    "\n",
    "# Aggregazione delle vendite a livello 'year-month-state' per calcolare le proporzioni storiche\n",
    "statewise_monthly_sales = df_cleaned.groupby(['Year-Month', 'State'])['Sales'].sum().reset_index()\n",
    "\n",
    "# Calcolo della proporzione delle vendite per stato rispetto al totale mensile\n",
    "total_monthly_sales = statewise_monthly_sales.groupby('Year-Month')['Sales'].sum().reset_index()\n",
    "statewise_monthly_sales = pd.merge(statewise_monthly_sales, total_monthly_sales, on='Year-Month', suffixes=('', '_Total'))\n",
    "statewise_monthly_sales['Sales_Proportion'] = statewise_monthly_sales['Sales'] / statewise_monthly_sales['Sales_Total']\n",
    "\n",
    "# Usare l'ultimo mese disponibile per calcolare le proporzioni di disaggregazione\n",
    "last_known_month = statewise_monthly_sales[statewise_monthly_sales['Year-Month'] == statewise_monthly_sales['Year-Month'].max()]\n",
    "\n",
    "# Disaggregare le previsioni basandosi sulle proporzioni dell'ultimo mese disponibile\n",
    "disaggregated_forecast = []\n",
    "\n",
    "for _, forecast_row in forecast_df.iterrows():\n",
    "    forecast_month = forecast_row['Year-Month'].to_period('M')  # Assicurati che questo sia un Period\n",
    "    forecast_value = forecast_row['Forecasted Sales']\n",
    "    \n",
    "    # Applica le proporzioni storiche di ciascuno stato\n",
    "    for _, proportion_row in last_known_month.iterrows():\n",
    "        state = proportion_row['State']\n",
    "        proportion = proportion_row['Sales_Proportion']\n",
    "        state_forecast = forecast_value * proportion\n",
    "        \n",
    "        disaggregated_forecast.append({\n",
    "            'Year-Month': forecast_month,\n",
    "            'State': state,\n",
    "            'Forecasted Sales': state_forecast\n",
    "        })\n",
    "\n",
    "# Converti le previsioni disaggregate in un DataFrame\n",
    "disaggregated_forecast_df = pd.DataFrame(disaggregated_forecast)\n",
    "\n",
    "# Mostra il risultato delle previsioni disaggregate\n",
    "print(disaggregated_forecast_df.head())\n",
    "\n",
    "### VALUTAZIONE A LIVELLO DI STATO ###\n",
    "# Unisci i dati reali con le previsioni\n",
    "merged_df = pd.merge(\n",
    "    disaggregated_forecast_df,\n",
    "    statewise_monthly_sales[statewise_monthly_sales['Year-Month'] >= '2018-01-01'],\n",
    "    on=['Year-Month', 'State'],\n",
    "    how='left',\n",
    "    suffixes=('_Forecast', '_Actual')\n",
    ")\n",
    "\n",
    "# Calcola le metriche per ciascuno stato\n",
    "metrics = []\n",
    "\n",
    "# Itera attraverso ciascuno stato\n",
    "for state in merged_df['State'].unique():\n",
    "    state_data = merged_df[merged_df['State'] == state]\n",
    "    \n",
    "    # Calcola MAE\n",
    "    mae = np.mean(np.abs(state_data['Forecasted Sales'] - state_data['Sales']))\n",
    "    \n",
    "    # Calcola RMSE\n",
    "    rmse = np.sqrt(np.mean((state_data['Forecasted Sales'] - state_data['Sales']) ** 2))\n",
    "    \n",
    "    # Calcola MAPE, evitando divisione per zero\n",
    "    mape = np.mean(np.abs((state_data['Forecasted Sales'] - state_data['Sales']) / state_data['Sales'])) * 100\n",
    "\n",
    "    metrics.append({\n",
    "        'State': state,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame con i risultati\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Mostra le metriche per ciascuno stato\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Best parameters found:  {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150, 'subsample': 0.8}\n",
      "Mean Absolute Error (MAE) - XGBoost: 15656.003038281251\n",
      "Root Mean Squared Error (RMSE) - XGBoost: 18505.023312138004\n",
      "Mean Absolute Percentage Error (MAPE) - XGBoost: 23.81630189410809%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definisci i parametri da ottimizzare\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Crea il modello XGBoost\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Crea la ricerca a griglia\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Esegui la ricerca\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Stampa i migliori parametri\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Utilizza il miglior modello per fare previsioni\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcola le metriche di errore\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred)\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape_xgb = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "# Stampa delle metriche di errore\n",
    "print(f'Mean Absolute Error (MAE) - XGBoost: {mae_xgb}')\n",
    "print(f'Root Mean Squared Error (RMSE) - XGBoost: {rmse_xgb}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) - XGBoost: {mape_xgb}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
